---
- name: Create lb virtual machine
  vars:
    vm_name: "lb.sandbox.okd.local"
    images_path: "/home/{{ ansible_user_id }}/.okd/images"
    vm_path: "/home/{{ ansible_user_id }}/.okd/vms/{{ vm_name }}"
    boot_init_iso_path: "{{ vm_path }}/boot-init.iso"
    centos7_cloud_image_name: CentOS-7-x86_64-GenericCloud-1907.qcow2
    centos7_cloud_image_url: "https://cloud.centos.org/centos/7/images/{{ centos7_cloud_image_name }}"
    mac: "52:54:00:00:05:57"
    ip: "10.0.5.57"
    dns_ip: "10.0.6.10"
    bridge: "virbr1"
    ssh_public_key: "/home/{{ ansible_user_id }}/.ssh/id_rsa.pub"
    dns_name: "lb.sandbox.okd.local"
  block:
    - name: List virtual machines
      virt:
        command: list_vms
        uri: "qemu:///session"
      register: vms
    - name: Create {{ vm_name }} virtual machine
      block:
        - name: Create {{ vm_name }} virtual machine directories
          file:
            path: "{{ item }}"
            state: directory
            owner: "{{ ansible_user_id }}"
            group: "{{ ansible_user_id }}"
          with_items:
            - "{{ images_path }}"
            - "{{ vm_path }}"
        - name: Check if centos 7 cloud image is present
          stat:
            path: "{{ images_path }}/{{ centos7_cloud_image_name }}"
          register: centos7_cloud_image
        - name: Download centos 7 cloud image
          become: no
          get_url:
            url: "{{ centos7_cloud_image_url }}"
            dest: "{{ images_path }}"
            sha256sum: "520d01c2f2e1ed24cb2f15a4325aa30773930a2961b5484a68cf11b4a415c512"
          when: centos7_cloud_image.stat.exists == False
        - name: Copy centos7 cloud image from images to {{ vm_name }} virtual machine
          copy:
            src: "{{ images_path }}/{{ centos7_cloud_image_name }}"
            dest: "{{ vm_path }}/{{ centos7_cloud_image_name }}"
            owner: "{{ ansible_user_id }}"
            group: "{{ ansible_user_id }}"
            force: no
        - name: Create meta-data file
          copy:
            dest: "{{ vm_path }}/meta-data"
            content: |
              instance-id: {{ vm_name }}
              local-hostname: {{ vm_name }}
        - name: |
            Create user-data file.
            Full Qualified Domain Name are used (instead of ip) to increase readibility and to use dynamic ip - which will not be the case here.
            BIG plus: haproxy will fail to start if a fqdn can not be resolved and that very cool to ensure that configuration
            is well defined.
            To know if the conf is valid do it inside the virtual machine: haproxy -c -f /etc/haproxy/haproxy.cfg
          copy:
            dest: "{{ vm_path }}/user-data"
            content: |
              #cloud-config

              # Hostname management
              preserve_hostname: False
              hostname: {{ vm_name }}
              fqdn: {{ vm_name }}.sandbox.okd.local
              manage_etc_hosts: true

              # Users
              users:
                  - default
                  - name: {{ ansible_user_id }}
                    groups: ['wheel']
                    shell: /bin/bash
                    sudo: ALL=(ALL) NOPASSWD:ALL
                    ssh-authorized-keys:
                      - {{ lookup('file', ssh_public_key) }}

              # Configure where output will go
              output:
                all: ">> /var/log/cloud-init.log"

              # configure interaction with ssh server
              ssh_genkeytypes: ['ed25519', 'rsa']

              # Install my public ssh key to the first user-defined user configured
              # in cloud.cfg in the template (which is centos for CentOS cloud images)
              ssh_authorized_keys:
                - {{ lookup('file', ssh_public_key) }}

              timezone: US/Eastern

              packages:
                - haproxy
                - bind-utils

              write_files:
                - content: |
                    # Global settings
                    #---------------------------------------------------------------------
                    global
                        maxconn     20000
                        log         /dev/log local0 info
                        chroot      /var/lib/haproxy
                        pidfile     /var/run/haproxy.pid
                        user        haproxy
                        group       haproxy
                        daemon

                        # turn on stats unix socket
                        stats socket /var/lib/haproxy/stats

                    #---------------------------------------------------------------------
                    # common defaults that all the 'listen' and 'backend' sections will
                    # use if not designated in their block
                    #---------------------------------------------------------------------
                    defaults
                        mode                    http
                        log                     global
                        option                  httplog
                        option                  dontlognull
                        option http-server-close
                        option forwardfor       except 127.0.0.0/8
                        option                  redispatch
                        retries                 3
                        timeout http-request    10s
                        timeout queue           1m
                        timeout connect         10s
                        timeout client          300s
                        timeout server          300s
                        timeout http-keep-alive 10s
                        timeout check           10s
                        maxconn                 20000

                    listen stats
                        bind :9000
                        mode http
                        stats enable
                        stats uri /

                    frontend ocp4_k8s_api_fe
                        bind :6443
                        default_backend ocp4_k8s_api_be
                        mode tcp
                        option tcplog

                    backend ocp4_k8s_api_be
                        balance roundrobin
                        mode tcp
                        server      bootstrap bootstrap.sandbox.okd.local:6443 check
                        server      control-plane-0 control-plane-0.sandbox.okd.local:6443 check
                        server      control-plane-1 control-plane-1.sandbox.okd.local:6443 check
                        server      control-plane-2 control-plane-2.sandbox.okd.local:6443 check

                    frontend ocp4_machine_config_server_fe
                        bind :22623
                        default_backend ocp4_machine_config_server_be
                        mode tcp
                        option tcplog

                    backend ocp4_machine_config_server_be
                        balance roundrobin
                        mode tcp
                        server      bootstrap bootstrap.sandbox.okd.local:22623 check
                        server      control-plane-0 control-plane-0.sandbox.okd.local:22623 check
                        server      control-plane-1 control-plane-1.sandbox.okd.local:22623 check
                        server      control-plane-2 control-plane-2.sandbox.okd.local:22623 check

                    frontend ocp4_http_ingress_traffic_fe
                        bind :80
                        default_backend ocp4_http_ingress_traffic_be
                        mode tcp
                        option tcplog

                    backend ocp4_http_ingress_traffic_be
                        balance roundrobin
                        mode tcp
                        server      compute-0 compute-0.sandbox.okd.local:80 check
                        server      compute-1 compute-1.sandbox.okd.local:80 check
                        server      compute-2 compute-2.sandbox.okd.local:80 check

                    frontend ocp4_https_ingress_traffic_fe
                        bind :443
                        default_backend ocp4_https_ingress_traffic_be
                        mode tcp
                        option tcplog

                    backend ocp4_https_ingress_traffic_be
                        balance roundrobin
                        mode tcp
                        server      compute-0 compute-0.sandbox.okd.local:443 check
                        server      compute-1 compute-1.sandbox.okd.local:443 check
                        server      compute-2 compute-2.sandbox.okd.local:443 check
                  path: /run/myconf/haproxy.cfg
                - content: |
                    supersede domain-name-servers {{ dns_ip }};
                    timeout 300;
                    retry 60;
                  path: /etc/dhcp/dhclient.conf

              # The message is located in /var/log/cloud-init.log
              final_message: "The system is finally up, after $UPTIME seconds"

              # Remove cloud-init when finished with it
              runcmd:
                - systemctl stop network && systemctl start network
                - systemctl disable cloud-init.service
                - /bin/cp /run/myconf/haproxy.cfg /etc/haproxy/haproxy.cfg
                - setsebool -P haproxy_connect_any on
                - systemctl start haproxy
                - systemctl enable haproxy
        - name: Create boot init iso
          shell:
            cmd: genisoimage -output {{ boot_init_iso_path }} -volid cidata -joliet -r {{ vm_path }}/user-data {{ vm_path }}/meta-data
        - name: Define {{ vm_name }} virtual machine
          virt:
            command: define
            name: "{{ vm_name }}"
            xml: '{{ lookup("template", "templates/vm.xml.j2") }}'
            uri: "qemu:///session"
          vars:
            name: "{{ vm_name }}"
            memory: 1024
            vcpus: 1
            disk_file: "{{ vm_path }}/{{ centos7_cloud_image_name }}"
            boot_init_iso: "{{ boot_init_iso_path }}"
            vm_mac: "{{ mac }}"
            vm_bridge: "{{ bridge }}"
        - name: Start {{ vm_name }} vm
          virt:
            command: start
            name: "{{ vm_name }}"
            autostart: yes
            uri: "qemu:///session"
        - name: Wait for port 22
          wait_for:
            host: "{{ ip }}"
            port: 22
            state: drained
            delay: 10
        - name: |
            Add {{ vm_name }} host to known_hosts - need to retry as ssh is not available yet after the port 22 is open
            An empty valide response can be returned :(
          block:
            - name: Retrieve dns virtual machine public key
              shell: ssh-keyscan -t ssh-rsa {{ ip }}
              register: task_result
              until: task_result.rc == 0 and task_result.stdout != ''
              retries: 120
              delay: 5
            - debug:
                msg: "{{ task_result }}"
            - name: Write dns virtual machine public key into Host known hosts
              lineinfile:
                path: /home/{{ ansible_user_id }}/.ssh/known_hosts
                insertafter: EOF
                line: "{{ dns_name }},{{ task_result.stdout }}"
                backup: yes
        - name: Remove boot-init.iso from {{ vm_name }} vm
          shell:
            cmd: virsh change-media {{ vm_name }} --path {{ boot_init_iso_path }} --eject --config
        - name: Wait until {{ vm_name }} virtual machine is ready
          shell: ssh centos@{{ ip }} 'sudo grep -nri "The system is finally up" /var/log/cloud-init.log' > /dev/null
          register: task_result
          until: task_result.rc == 0
          retries: 120
          delay: 5
        - name: Check {{ vm_name }} haproxy service is active
          block:
            - name: Get {{ vm_name }} haproxy service status
              shell: ssh centos@{{ ip }} 'sudo systemctl is-active haproxy'
              register: is_active
              until: is_active.stdout != ''
              retries: 120
              delay: 10
            - debug:
                msg: "{{ is_active }}"
            - name: Ensure {{ vm_name }} haproxy service is active
              assert:
                that:
                  - "'active' == is_active.stdout"
      when: vm_name not in vms.list_vms

    - name: Should {{ vm_name }} virtual machine is well configured
      block:
        - name: Check dns virtual machine is resolvable in {{ vm_name }} VM
          block:
            - name: Execute dns virtual machine resolution in {{ vm_name }} VM
              shell: ssh centos@{{ ip }} 'dig dns.okd.local +short'
              register: ip_resolved
            - debug:
                msg: "{{ ip_resolved }}"
            - name: Ensure ip resolved to dns virtual machine ip
              assert:
                that:
                  - "'{{ dns_ip }}' == ip_resolved.stdout"
        - name: Check external dns resolution is working in {{ vm_name }} VM
          block:
            - name: Execute Host resolution
              shell: ssh centos@{{ ip }} 'dig google.fr +short'
              register: ips_resolved
            - debug:
                msg: "{{ ips_resolved }}"
            - name: Ensure external host is resolved
              assert:
                that:
                  - "ips_resolved is defined"
                  - "ips_resolved.stdout_lines is defined"
                  - "ips_resolved.stdout_lines|length > 0"