---
- name: Create control plane {{ item.index }} virtual machine
  vars:
    vm_name: "control_plane_{{ item.index }}"
    ip: "{{ item.ip }}"
    mac: "{{ item.mac }}"
    images_path: "/home/{{ ansible_user_id }}/.okd/images"
    fedora_coreos_cloud_image_name: "fedora-coreos-31.20200310.3.0-qemu.x86_64.qcow2"
    vms_path: "/home/{{ ansible_user_id }}/.okd/vms"
  block:
    - name: Create {{ vm_name }} virtual machine
      block:
        - name: Create {{ vm_name }} virtual machine directory
          file:
            path: "{{ vms_path }}/{{ vm_name }}"
            state: directory
            owner: "{{ ansible_user_id }}"
            group: "{{ ansible_user_id }}"
        - name: Copy fedora coreos cloud image from images to {{ vm_name }} virtual machine directory
          copy:
            src: "{{ images_path }}/{{ fedora_coreos_cloud_image_name }}"
            dest: "{{ vms_path }}/{{ vm_name }}/{{ fedora_coreos_cloud_image_name }}"
            owner: "{{ ansible_user_id }}"
            group: "{{ ansible_user_id }}"
            force: no
        - name: Resize image to add 25G more space
          shell: qemu-img resize {{ vms_path }}/{{ vm_name }}/{{ fedora_coreos_cloud_image_name }} 25G
        - name: Define {{ vm_name }} virtual machine into kvm
          virt:
            command: define
            name: "{{ vm_name }}"
            xml: '{{ lookup("template", "templates/vm.xml.j2") }}'
            uri: "qemu:///session"
          vars:
            name: "{{ vm_name }}"
            memory: 8192
            vcpus: 1
            disk_file: "{{ vms_path }}/{{ vm_name }}/{{ fedora_coreos_cloud_image_name }}"
            vm_mac: "{{ mac }}"
            vm_bridge: "virbr-okd-cl0"
            fw_cfg: "name=opt/com.coreos/config,file=/tmp/master.ign"
        - name: Start {{ vm_name }} virtual machine
          virt:
            command: start
            name: "{{ vm_name }}"
            autostart: yes
            uri: "qemu:///session"
        - name: |
            Wait for port 22.
          wait_for:
            host: "{{ ip }}"
            port: 22
            state: drained
            delay: 10
        - name: |
            Add {{ vm_name }} virtual machine to host known_hosts - need to retry as ssh is not available yet after the port 22 is open.
          shell: |
            while [ -z "$knownHost" ]
            do
              sleep 1
              knownHost=$(ssh-keyscan -t ssh-rsa {{ ip }})
            done
            echo "$knownHost" >> "/home/{{ ansible_user_id }}/.ssh/known_hosts"
          args:
            executable: /bin/bash
        - name: |
            Wait until unprivilegied {{ ansible_user_id }} can loggin in using ssh to avoid this message:
#            fatal: [localhost]: FAILED! => {"changed": true, "cmd": "ssh core@10.0.5.59 'dig test.apps.ocp4-cluster-001.sandbox.okd +short'", "delta": "0:00:00.102321", "end": "2020-04-11 19:56:50.886226", "msg": "non-zero return code", "rc": 255, "start": "2020-04-11 19:56:50.783905", "stderr": "\"System is booting up. Unprivileged users are not permitted to log in yet. Please come back later. For technical details, see pam_nologin(8).\"\nAuthentication failed.", "stderr_lines": ["\"System is booting up. Unprivileged users are not permitted to log in yet. Please come back later. For technical details, see pam_nologin(8).\"", "Authentication failed."], "stdout": "", "stdout_lines": []}
          shell: |
            ssh {{ ansible_user_id }}@{{ ip }} 'date'
            while [ $? -ne 0 ]; do
              sleep 1
              ssh {{ ansible_user_id }}@{{ ip }} 'date'
            done
# TODO nope je dois tester que le container-registry est accessible !!!
    - name: Should {{ vm_name }} virtual machine is well configured
      block:
        - name: Should wildcard *.apps.ocp4-cluster-001.sandbox.okd on {{ vm_name }} virtual machine resolve to load balander
          block:
            - name: Execute Host resolution
              shell: ssh {{ ansible_user_id }}@{{ ip }} 'dig test.apps.ocp4-cluster-001.sandbox.okd +short'
              register: ip_resolved
            - debug:
                msg: "{{ ip_resolved }}"
            - name: Ensure ip resolved to dns virtual machine ip
              assert:
                that:
                  - "'10.0.5.57' == ip_resolved.stdout"
        - name: Should external dns resolution is working in {{ vm_name }} virtual machine
          block:
            - name: Execute external DNS resolution
              shell: ssh {{ ansible_user_id }}@{{ ip }} 'dig google.fr +short'
              register: ips_resolved
            - debug:
                msg: "{{ ips_resolved }}"
            - name: Ensure external host is resolved
              assert:
                that:
                  - "ips_resolved is defined"
                  - "ips_resolved.stdout_lines is defined"
                  - "ips_resolved.stdout_lines|length > 0"
    - name: Restart machine-config-daemon-firstboot.service if it has failed to start on {{ vm_name }} virtual machine
# fatal: [localhost]: FAILED! => {"changed": true, "cmd": "ssh damien@10.0.5.59 'sudo systemctl restart machine-config-daemon-firstboot.service'", "delta": "0:01:18.110876", "end": "2020-04-11 21:22:46.652586", "msg": "non-zero return code", "rc": 1, "start": "2020-04-11 21:21:28.541710", "stderr": "Job for machine-config-daemon-firstboot.service canceled.", "stderr_lines": ["Job for machine-config-daemon-firstboot.service canceled."], "stdout": "", "stdout_lines": []}
      shell: |
        isFailed=$(ssh {{ ansible_user_id }}@{{ ip }} 'sudo systemctl is-failed machine-config-daemon-firstboot.service')
        if [[ "$isFailed" == "failed" ]]; then
          ssh {{ ansible_user_id }}@{{ ip }} 'sudo systemctl restart machine-config-daemon-firstboot.service'
          while [ $? -ne 0 ]; do
            sleep 1
            ssh {{ ansible_user_id }}@{{ ip }} 'sudo systemctl restart machine-config-daemon-firstboot.service'
          done
        fi